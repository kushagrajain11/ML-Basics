{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_for_gradient(X_train, Y_train, alpha, m) :\n",
    "    slope = np.array([0 for i in range(len(m))])\n",
    "    \n",
    "    for i in range(len(X_train)) :\n",
    "        for j in range(len(slope)) :\n",
    "            slope[j] += (2)*X_train[i][j]*(m.dot(X_train[i]) - Y_train[i])\n",
    "\n",
    "    m = m - slope*(alpha/len(X_train))\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "def fit(X_train, Y_train, alpha, num_iterations) :\n",
    "    X_train = X_train.as_matrix()\n",
    "    ones_column = np.ones((len(X_train), 1), dtype = float)\n",
    "    np.append(X_train, ones_column, axis = 1)\n",
    "    m = np.array([0 for i in range(len(X_train[0]))])\n",
    "    \n",
    "    for i in range(num_iterations) :\n",
    "        print(\"Cost = \", cost(X_train, Y_train, m))\n",
    "        m = one_step_for_gradient(X_train, Y_train, alpha, m)\n",
    "        \n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "def predict(X_test, m) :\n",
    "    X_test = X_test.as_matrix()\n",
    "    ones_column = np.ones((len(X_test), 1), dtype = float)\n",
    "    np.append(X_test, ones_column, axis = 1)\n",
    "    \n",
    "    return [m.dot(current_row) for current_row in X_test]\n",
    "\n",
    "\n",
    "\n",
    "def cost(x, y, m) :\n",
    "    temp = 0\n",
    "    \n",
    "    for i in range(len(x)) :\n",
    "        temp += (y[i] - m.dot(x[i]))**2\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "dataframe = pd.DataFrame(diabetes.data)\n",
    "dataframe.columns = diabetes.feature_names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataframe, diabetes.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost =  10429569.0\n",
      "Cost =  10429406.5688\n",
      "Cost =  10429244.153\n",
      "Cost =  10429081.8113\n",
      "Cost =  10428919.5046\n",
      "Cost =  10428757.2242\n",
      "Cost =  10428594.9591\n",
      "Cost =  10428432.7558\n",
      "Cost =  10428270.5999\n",
      "Cost =  10428108.4592\n",
      "Cost =  10427946.3752\n",
      "Cost =  10427784.3565\n",
      "Cost =  10427622.3619\n",
      "Cost =  10427460.3827\n",
      "Cost =  10427298.4518\n",
      "Cost =  10427136.5639\n",
      "Cost =  10426974.6914\n",
      "Cost =  10426812.843\n",
      "Cost =  10426651.0378\n",
      "Cost =  10426489.2478\n",
      "Cost =  10426327.5204\n",
      "Cost =  10426165.8253\n",
      "Cost =  10426004.1625\n",
      "Cost =  10425842.515\n",
      "Cost =  10425680.8827\n",
      "Cost =  10425519.2657\n",
      "Cost =  10425357.6747\n",
      "Cost =  10425196.1119\n",
      "Cost =  10425034.583\n",
      "Cost =  10424873.1192\n",
      "Cost =  10424711.6601\n",
      "Cost =  10424550.2441\n",
      "Cost =  10424388.8433\n",
      "Cost =  10424227.4706\n",
      "Cost =  10424066.1264\n",
      "Cost =  10423904.8195\n",
      "Cost =  10423743.5278\n",
      "Cost =  10423582.2792\n",
      "Cost =  10423421.0678\n",
      "Cost =  10423259.8922\n",
      "Cost =  10423098.7318\n",
      "Cost =  10422937.5867\n",
      "Cost =  10422776.4567\n",
      "Cost =  10422615.3918\n",
      "Cost =  10422454.3509\n",
      "Cost =  10422293.3438\n",
      "Cost =  10422132.3494\n",
      "Cost =  10421971.3703\n",
      "Cost =  10421810.4063\n",
      "Cost =  10421649.4575\n",
      "Cost =  10421488.6068\n",
      "Cost =  10421327.8118\n",
      "Cost =  10421167.0794\n",
      "Cost =  10421006.4156\n",
      "Cost =  10420845.8558\n",
      "Cost =  10420685.3432\n",
      "Cost =  10420524.8456\n",
      "Cost =  10420364.3853\n",
      "Cost =  10420203.9489\n",
      "Cost =  10420043.5276\n",
      "Cost =  10419883.1215\n",
      "Cost =  10419722.7305\n",
      "Cost =  10419562.3715\n",
      "Cost =  10419402.0712\n",
      "Cost =  10419241.7859\n",
      "Cost =  10419081.5466\n",
      "Cost =  10418921.3265\n",
      "Cost =  10418761.1214\n",
      "Cost =  10418600.9334\n",
      "Cost =  10418440.7605\n",
      "Cost =  10418280.6247\n",
      "Cost =  10418120.5361\n",
      "Cost =  10417960.5034\n",
      "Cost =  10417800.52\n",
      "Cost =  10417640.5677\n",
      "Cost =  10417480.693\n",
      "Cost =  10417320.8334\n",
      "Cost =  10417161.0073\n",
      "Cost =  10417001.2265\n",
      "Cost =  10416841.4607\n",
      "Cost =  10416681.7695\n",
      "Cost =  10416522.1119\n",
      "Cost =  10416362.4692\n",
      "Cost =  10416202.8524\n",
      "Cost =  10416043.2292\n",
      "Cost =  10415883.6483\n",
      "Cost =  10415724.0824\n",
      "Cost =  10415564.5316\n",
      "Cost =  10415404.9958\n",
      "Cost =  10415245.4774\n",
      "Cost =  10415085.9898\n",
      "Cost =  10414926.5279\n",
      "Cost =  10414767.081\n",
      "Cost =  10414607.6492\n",
      "Cost =  10414448.2885\n",
      "Cost =  10414288.9429\n",
      "Cost =  10414129.6307\n",
      "Cost =  10413970.3166\n",
      "Cost =  10413811.0176\n",
      "Cost =  10413651.77\n"
     ]
    }
   ],
   "source": [
    "m = fit(X_train, Y_train, alpha = 0.007, num_iterations = 100)\n",
    "Y_pred = predict(X_test, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04030597003397618, 0.68187095580383539, 0.0096144364482910472, -0.82411598849214518, 0.034517699815497252, -0.18074005418436229, -0.63059492102119874, 0.60471431293697009, 0.37299013405905668, 0.59399683174756657, 0.059339595837827205, -0.72143120905662528, 0.23308296093381464, -0.14912562912568275, -0.70998949964923341, 0.18393350657709018, -0.38084668990334991, 0.50774812662741986, -0.32573381834355264, 0.3269696664318873, 0.19278459255006414, -0.26199365114590883, -0.82611358369268229, 0.22594970628267463, -0.16055806307183695, -0.79045607715156574, 0.72932680869083688, 0.57117383243121633, 0.16929088860965627, -0.20281785906954808, -0.29458321295138395, 0.1538230283408823, -0.61076611752589471, 0.3276668049163583, 0.37840289149804651, 0.13515942834693936, 0.489622113351389, -0.77473381352256798, 0.15347529546567301, -0.65757197794011868, 0.48921396218184743, 0.16279008959919114, 0.31543863841588987, 0.086658350414288585, -0.92243817739848799, -0.060770001604982637, -0.25043801713368835, -0.35011594836472271, -0.57129027972451085, -0.14843934396085029, 0.77806752293186188, 0.080857183320147297, 0.27900886982618056, 0.37297308857903205, 0.043971357485637644, 0.3481946926139487, -0.71355107464713297, 0.17676364449737939, -0.016269995800348713, -0.044451257545030383, 0.53102539802311766, 0.42988331028399041, -0.011946601937366533, 0.59292764140568421, -0.055125898759340763, -0.38149205421688148, -0.27499283465408259, 1.1317150084116774, -0.21384696937913117, 0.76769777585808097, 0.44946204424308456, -0.28622722875143669, 0.25571204865956348, 0.62874956620534506, 0.52051094483671534, -0.23054282830506406, 0.26397432335800119, -0.3901975595527809, 0.20242479619199588, -0.65948049274994425, -0.62031182126194906, -0.60893074279381287, -0.799549561474866, -0.71636906407015999, 0.79205431375372148, 0.27573459048388588, 0.84844076835993787, -0.087920467117306472, 0.30469161472541356] \n",
      "\n",
      "[  65.  139.   51.   77.  191.  214.   98.  152.  281.  215.   58.   51.\n",
      "  202.   55.   65.  185.   63.  296.  127.  116.  288.   55.   59.   91.\n",
      "  200.  134.  263.  173.  126.  172.  214.  161.   55.  235.   67.  202.\n",
      "  120.   96.   85.   61.  197.  265.  142.  225.   37.   42.   88.   75.\n",
      "   77.  258.  341.  111.  168.  277.   48.  259.  142.   77.   90.   97.\n",
      "  270.  128.   71.  297.  170.  162.  252.  230.   97.  180.  233.  135.\n",
      "   63.  192.  150.   95.  142.   94.   89.   43.  128.   87.   90.   75.\n",
      "  281.  109.  233.  141.  179.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred, \"\\n\")\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
